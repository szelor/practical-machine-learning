rxAuc(roc(data = gb_model_prediction,
observed = "label1",
predicted = "Probability.1"))
#Stacking
?MicrosoftML::rxEnsemble
ensemble_model <- rxEnsemble(
formula = formula,
data = train_df,
type = "binary",
trainers = list(
logisticRegression(),
logisticRegression(l1Weight = 0.9,
l2Weight = 0.9,
normalize = "warn"),
fastTrees(numTrees = 20,
exampleFraction = 0.6,
featureFraction = 0.9,
learningRate = 0.01,
unbalancedSets = FALSE,
numLeaves = 10,
minSplit = 5,
splitFraction = 0.8),
fastForest(numTrees = 10,
numLeaves = 15,
exampleFraction = 0.6,
featureFraction = 0.7,
splitFraction = 0.6,
minSplit = 15)),
replace = TRUE,
modelCount = 8,
combineMethod = "vote")
summary(ensemble_model)
ensemble_model_prediction <- rxPredict(modelObject = ensemble_model,
data = test_df,
extraVarsToWrite = "label1")
ensemble_model_metrics <- evaluate_classifier(actual = "label1",
predicted = "PredictedLabel",
data = ensemble_model_prediction)
ensemble_model_metrics
model_factory <- function(train_table_name, test_table_name, top_variables) {
train_table <- RxSqlServerData(table = train_table_name,
connectionString = connection_string,
colInfo = list(label1 = list(type = "factor", levels = c("0", "1"))))
train_df <- rxImport(train_table)
test_table <- RxSqlServerData(table = test_table_name,
connectionString = connection_string,
colInfo = list(label1 = list(type = "factor", levels = c("0", "1"))))
test_df <- rxImport(test_table)
# Find top n variables most correlated with label1
train_vars <- rxGetVarNames(train_df)
train_vars <- train_vars[!train_vars  %in% c("RUL", "label2", "id", "cycle_orig","cycle")]
formula <- as.formula(paste("~", paste(train_vars, collapse = "+")))
correlation <- rxCor(formula = formula,
data = train_df,
transforms = list(label1 = as.numeric(label1)))
correlation <- correlation[, "label1"]
correlation <- abs(correlation)
correlation <- correlation[order(correlation, decreasing = TRUE)]
correlation <- correlation[-1]
correlation <- correlation[1:top_variables]
formula <- as.formula(paste(paste("label1~"),
paste(names(correlation), collapse = "+")))
# Logistic Regression - binary classification using L-BFGS
logit_model <- MicrosoftML::rxLogisticRegression(formula = formula,
data = train_df,
type = "binary",
l1Weight = 0.9,
l2Weight = 0.9,
maxIterations = 100,
optTol = 1e-07,
normalize = "warn",
memorySize = 100)
logit_model_prediction <- rxPredict(modelObject = logit_model,
data = test_df,
extraVarsToWrite = "label1",
overwrite = TRUE)
logit_model_metrics <<- evaluate_classifier(actual = "label1", predicted = "PredictedLabel",
data = logit_model_prediction)
# Neural networks
nn_model <- MicrosoftML::rxNeuralNet(formula,
data = train_df,
type = "binary",
normalize = "auto",
numIterations = 100,
optimizer = adaDeltaSgd(),
numHiddenNodes = 5,
initWtsDiameter = 0.05)
nn_model_prediction <- rxPredict(modelObject = nn_model,
data = test_df,
extraVarsToWrite = "label1",
overwrite = TRUE)
nn_model_prediction$newLabel1 <- ifelse(nn_model_prediction$Probability.1<=0.4, 0,1)
nn_model_metrics <<- evaluate_classifier(actual = "label1", predicted = "newLabel1",
data = nn_model_prediction)
#Random forest
random_forest_model <- MicrosoftML::rxFastForest(formula,
data = train_df,
type = "binary",
numTrees = 10,
numLeaves = 15,
exampleFraction = 0.6,
featureFraction = 0.7,
splitFraction = 0.6,
minSplit = 15)
rf_model_prediction <- rxPredict(modelObject = random_forest_model,
data = test_df,
extraVarsToWrite = "label1",
overwrite = TRUE)
rf_model_metrics <<- evaluate_classifier(actual = "label1", predicted = "PredictedLabel",
data = rf_model_prediction)
#MART gradient boosting
gradient_boosting_model <- MicrosoftML::rxFastTrees(formula,
data = train_df,
type = "binary",
numTrees = 20,
exampleFraction = 0.6,
featureFraction = 0.9,
learningRate = 0.01,
unbalancedSets = FALSE,
numLeaves = 10,
minSplit = 5,
splitFraction = 0.8)
gb_model_prediction <- rxPredict(modelObject = gradient_boosting_model,
data = test_df,
extraVarsToWrite = "label1",
overwrite = TRUE)
gb_model_metrics <<- evaluate_classifier(actual = "label1", predicted = "PredictedLabel",
data = gb_model_prediction)
ensemble_model <- MicrosoftML::rxEnsemble(
formula = formula,
data = train_df,
type = "binary",
trainers = list(
logisticRegression(),
logisticRegression(l1Weight = 0.9,
l2Weight = 0.9,
normalize = "warn"),
fastTrees(numTrees = 20,
exampleFraction = 0.6,
featureFraction = 0.9,
learningRate = 0.01,
unbalancedSets = FALSE,
numLeaves = 10,
minSplit = 5,
splitFraction = 0.8),
fastForest(numTrees = 10,
numLeaves = 15,
exampleFraction = 0.6,
featureFraction = 0.7,
splitFraction = 0.6,
minSplit = 15)),
replace = TRUE,
modelCount = 8,
combineMethod = "average")
ensemble_model_prediction <- rxPredict(modelObject = ensemble_model,
data = test_df,
extraVarsToWrite = "label1")
ensemble_model_metrics <<- evaluate_classifier(actual = "label1",
predicted = "PredictedLabel",
data = ensemble_model_prediction)
}
# Classification models evaluation metrics
evaluate_classifier <- function (actual, predicted, data, ...) {
varInfo <- rxGetVarInfo(data)
if (varInfo[[actual]]$varType != "factor") {
actual <- paste0("F(",actual,")")
}
if (varInfo[[predicted]]$varType != "factor") {
predicted <- paste0("F(",predicted,")")
}
myForm <- as.formula(paste("~",paste(actual,predicted, sep = ":")))
confusion <- rxCrossTabs(myForm,data = data, returnXtabs = TRUE, ...)
names(dimnames(confusion)) <- c("actual","predicted")
#print(confusion)
#print(prop.table(confusion))
tn <- confusion[1, 1]
fp <- confusion[1, 2]
fn <- confusion[2, 1]
tp <- confusion[2, 2]
#print(c(tp,fn,fp,tn))
accuracy <- (tp + tn) / (tp + fn + fp + tn)
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)
fscore <- 2 * (precision * recall) / (precision + recall)
metrics <- c("Accuracy" = accuracy,
"Precision" = precision,
"Recall" = recall,
"F-Score" = fscore)
return(metrics)
}
# Connection string and compute context
connection_string <- "Driver=SQL Server; Server=MS; Database=ML; Trusted_Connection=yes"
local <- RxLocalParallel()
rxSetComputeContext(local)
evaluate_classifier <- function (actual, predicted, data, ...) {
varInfo <- rxGetVarInfo(data)
if (varInfo[[actual]]$varType != "factor") {
actual <- paste0("F(",actual,")")
}
if (varInfo[[predicted]]$varType != "factor") {
predicted <- paste0("F(",predicted,")")
}
myForm <- as.formula(paste("~",paste(actual,predicted, sep = ":")))
cm <- rxCrossTabs(myForm,data = data, returnXtabs = TRUE, ...)
names(dimnames(cm)) <- c("actual","predicted")
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the classes
q = colsums / n # distribution of instances over the predicted classes
#accuracy
accuracy = sum(diag) / n
#per class prf
recall = diag / rowsums
precision = diag / colsums
f1 = 2 * precision * recall / (precision + recall)
#random/expected accuracy
expAccuracy = sum(p*q)
#kappa
kappa = (accuracy - expAccuracy) / (1 - expAccuracy)
#random guess
rgAccuracy = 1 / nc
rgPrecision = p
rgRecall = 0*p + 1 / nc
rgF1 = 2 * p / (nc * p + 1)
classNames = names(diag)
if(is.null(classNames)) classNames = paste("C",(1:nc),sep="")
metrics = rbind(
Accuracy = accuracy,
Precision = precision,
Recall = recall,
F1 = f1,
Kappa = kappa,
RandomGuessAccuracy = rgAccuracy,
RandomGuessPrecision = rgPrecision,
RandomGuessRecall = rgRecall,
RandomGuessF1 = rgF1)
colnames(metrics) = classNames
return(list(ConfusionMatrix = cm, Metrics = metrics))
}
# ROC curve
roc_curve <- function(data, observed, predicted) {
data <- data[, c(observed, predicted)]
data[[observed]] <- as.numeric(as.character(data[[observed]]))
rxRocCurve(actualVarName = observed,
predVarNames = predicted,
data = data)
}
roc <- function(data, observed, predicted) {
data <- data[, c(observed, predicted)]
data[[observed]] <- as.numeric(as.character(data[[observed]]))
rxRoc(actualVarName = observed,
predVarNames = predicted,
data = data)
}
train_table_name <- "PredictiveMaintenance.train_Features"
test_table_name <- "PredictiveMaintenance.test_Features"
top_variables <- 25
train_table <- RxSqlServerData(table = train_table_name,
connectionString = connection_string,
colInfo = list(label1 = list(type = "factor", levels = c("0", "1"))))
train_df <- rxImport(train_table)
test_table <- RxSqlServerData(table = test_table_name,
connectionString = connection_string,
colInfo = list(label1 = list(type = "factor", levels = c("0", "1"))))
test_df <- rxImport(test_table)
# Find top n variables most correlated with label1
train_vars <- rxGetVarNames(train_df)
train_vars <- train_vars[!train_vars  %in% c("RUL", "label2", "id", "cycle_orig","cycle")]
formula <- as.formula(paste("~", paste(train_vars, collapse = "+")))
correlation <- rxCor(formula = formula,
data = train_df,
transforms = list(label1 = as.numeric(label1)))
correlation <- correlation[, "label1"]
correlation <- abs(correlation)
correlation <- correlation[order(correlation, decreasing = TRUE)]
correlation <- correlation[-1]
correlation <- correlation[1:top_variables]
formula <- as.formula(paste(paste("label1~"),
paste(names(correlation), collapse = "+")))
formula
train_vars <- rxGetVarNames(train_df)
train_vars <- train_vars[!train_vars  %in% c("RUL", "label1", "id", "cycle_orig","cycle")]
formula <- as.formula(paste("~", paste(train_vars, collapse = "+")))
correlation <- rxCor(formula = formula,
data = train_df,
transforms = list(label1 = as.numeric(label1)))
correlation <- correlation[, "label2"]
correlation <- abs(correlation)
correlation <- correlation[order(correlation, decreasing = TRUE)]
correlation <- correlation[-1]
correlation <- correlation[1:top_variables]
formula <- as.formula(paste(paste("label1~"),
paste(names(correlation), collapse = "+")))
formula
formula
# Find top n variables most correlated with label2
train_vars <- rxGetVarNames(train_df)
train_vars <- train_vars[!train_vars  %in% c("RUL", "label1", "id", "cycle_orig","cycle")]
formula <- as.formula(paste("~", paste(train_vars, collapse = "+")))
correlation <- rxCor(formula = formula,
data = train_df,
transforms = list(label1 = as.numeric(label1)))
correlation <- correlation[, "label2"]
correlation <- abs(correlation)
correlation <- correlation[order(correlation, decreasing = TRUE)]
correlation <- correlation[-1]
correlation <- correlation[1:top_variables]
formula <- as.formula(paste(paste("label1~"),
paste(names(correlation), collapse = "+")))
formula
formula <- as.formula(paste(paste("label2~"),
paste(names(correlation), collapse = "+")))
formula
# Connection string and compute context
connection_string <- "Driver=SQL Server; Server=MS; Database=ML; Trusted_Connection=yes"
local <- RxLocalParallel()
rxSetComputeContext(local)
# Classification models evaluation metrics
evaluate_classifier <- function(actual=NULL, predicted=NULL, cm=NULL){
if(is.null(cm)) {
naVals = union(which(is.na(actual)), which(is.na(predicted)))
if(length(naVals) > 0) {
actual = actual[-naVals]
predicted = predicted[-naVals]
}
f = factor(union(unique(actual), unique(predicted)))
actual = factor(actual, levels = levels(f))
predicted = factor(predicted, levels = levels(f))
cm = as.matrix(table(Actual=actual, Predicted=predicted))
}
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the classes
q = colsums / n # distribution of instances over the predicted classes
#accuracy
accuracy = sum(diag) / n
#per class prf
recall = diag / rowsums
precision = diag / colsums
f1 = 2 * precision * recall / (precision + recall)
#macro prf
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
#1-vs-all matrix
oneVsAll = lapply(1 : nc,
function(i){
v = c(cm[i,i],
rowsums[i] - cm[i,i],
colsums[i] - cm[i,i],
n-rowsums[i] - colsums[i] + cm[i,i]);
return(matrix(v, nrow = 2, byrow = T))})
s = matrix(0, nrow=2, ncol=2)
for(i in 1:nc){s=s+oneVsAll[[i]]}
#avg accuracy
avgAccuracy = sum(diag(s))/sum(s)
#micro prf
microPrf = (diag(s) / apply(s,1, sum))[1];
#majority class
mcIndex = which(rowsums==max(rowsums))[1] # majority-class index
mcAccuracy = as.numeric(p[mcIndex])
mcRecall = 0*p;  mcRecall[mcIndex] = 1
mcPrecision = 0*p; mcPrecision[mcIndex] = p[mcIndex]
mcF1 = 0*p; mcF1[mcIndex] = 2 * mcPrecision[mcIndex] / (mcPrecision[mcIndex] + 1)
#random/expected accuracy
expAccuracy = sum(p*q)
#kappa
kappa = (accuracy - expAccuracy) / (1 - expAccuracy)
#random guess
rgAccuracy = 1 / nc
rgPrecision = p
rgRecall = 0*p + 1 / nc
rgF1 = 2 * p / (nc * p + 1)
classNames = names(diag)
if(is.null(classNames)) classNames = paste("C",(1:nc),sep="")
metrics = rbind(
Accuracy = accuracy,
Precision = precision,
Recall = recall,
F1 = f1,
MacroAvgPrecision = macroPrecision,
MacroAvgRecall = macroRecall,
MacroAvgF1 = macroF1,
AvgAccuracy = avgAccuracy,
MicroAvgPrecision = microPrf,
MicroAvgRecall = microPrf,
MicroAvgF1 = microPrf,
MajorityClassAccuracy = mcAccuracy,
MajorityClassPrecision = mcPrecision,
MajorityClassRecall = mcRecall,
MajorityClassF1 = mcF1,
Kappa = kappa,
RandomGuessAccuracy = rgAccuracy,
RandomGuessPrecision = rgPrecision,
RandomGuessRecall = rgRecall,
RandomGuessF1 = rgF1)
colnames(metrics) = classNames
return(list(ConfusionMatrix = cm, Metrics = metrics))
}
# Select variables
train_table_name <- "PredictiveMaintenance.train_Features"
test_table_name <- "PredictiveMaintenance.test_Features"
top_variables <- 20
train_table <- RxSqlServerData(table = train_table_name,
connectionString = connection_string,
colInfo = list(label2 = list(type = "factor",
levels = c("0", "1", "2"))))
train_df <- rxImport(train_table)
test_table <- RxSqlServerData(table = test_table_name,
connectionString = connection_string,
colInfo = list(label2 = list(type = "factor",
levels = c("0", "1", "2"))))
test_df <- rxImport(test_table)
# Find top n variables most correlated with label2
train_vars <- rxGetVarNames(train_df)
train_vars <- train_vars[!train_vars  %in% c("RUL", "label1", "id", "cycle_orig")]
formula <- as.formula(paste("~", paste(train_vars, collapse = "+")))
correlation <- rxCor(formula = formula,
data = train_df,
transforms = list(label2 = as.numeric(label2)))
correlation <- correlation[, "label2"]
correlation <- abs(correlation)
correlation <- correlation[order(correlation, decreasing = TRUE)]
correlation <- correlation[-1]
correlation <- correlation[1:top_variables]
formula <- as.formula(paste(paste("label2~"),
paste(names(correlation), collapse = "+")))
formula
# Logistic Regression - multiclass classification using L-BFGS
logit_model <- MicrosoftML::rxLogisticRegression(formula = formula,
data = train_df,
type = "multiClass",
l1Weight = 0.95,
l2Weight = 0.95,
optTol = 1e-05,
normalize = "no")
summary(logit_model)
str(logit_model)
logit_model_prediction <- rxPredict(modelObject = logit_model,
data = test_df,
extraVarsToWrite = "label2")
logit_model_metrics <- evaluate_classifier(actual = logit_model_prediction$label2,
logit_model_prediction$PredictedLabel)
logit_model_metrics
nn_model <- MicrosoftML::rxNeuralNet(formula,
data = train_df,
type = "multiClass",
normalize = "no",
numIterations = 5,
numHiddenNodes = 2,
optimizer = adaDeltaSgd(),
initWtsDiameter = 0.05,
maxNorm=2)
summary(nn_model)
nn_model_prediction <- rxPredict(modelObject = nn_model,
data = test_df,
extraVarsToWrite = "label2")
nn_model_metrics <- evaluate_classifier(actual = nn_model_prediction$label2,
predicted = nn_model_prediction$PredictedLabel)
nn_model_metrics
?RevoScaleR::rxDForest
forest_model <- RevoScaleR::rxDForest(formula = formula,
data = train_df,
method = "class",
nTree = 20,
mTry = 10,
replace = TRUE,
strata = "label2",
seed = 5,
maxDepth = 10,
cp = 0.002,
minSplit = 15,
maxNumBins = 200,
findSplitsInParallel = TRUE)
forest_model$confusion
forest_model_prediction <- rxPredict(modelObject = forest_model,
data = test_df,
extraVarsToWrite = "label2",
type = "prob")
forest_model_metrics <- evaluate_classifier(actual = forest_model_prediction$label2,
predicted = forest_model_prediction$label2_Pred)
forest_model_metrics$Metrics
forest_model_metrics
boosted_model <- RevoScaleR::rxBTrees(formula = formula,
data = train_df,
lossFunction = "multinomial",
learningRate = 0.05,
nTree = 25,
mTry = 10,
replace = FALSE,
sampRate = 0.632,
strata = "label2",
seed = 215,
cp = 0.01,
minSplit = 15,
minBucket = 8,
maxNumBins = 300)
summary(boosted_model)
boosted_model$forest
boosted_model_prediction <- rxPredict(modelObject = boosted_model,
data = test_df,
extraVarsToWrite = "label2",
type = "prob")
boosted_model_metrics <- evaluate_classifier(actual = boosted_model_prediction$label2,
boosted_model_prediction$label2_Pred)
boosted_model_metrics
